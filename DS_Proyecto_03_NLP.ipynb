{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GRQnxMzISE_"
   },
   "source": [
    "# Proyecto 03 - Procesamiento del Lenguaje Natural\n",
    "\n",
    "## Dataset: The Multilingual Amazon Reviews Corpus\n",
    "\n",
    "**Recuerda descargar el dataset de [aquí](https://github.com/kang205/SASRec). Es un archivo .zip que contiene tres documentos. Más información sobre el dataset [aquí](https://registry.opendata.aws/amazon-reviews-ml/). Es importante que tengas en cuenta la [licencia](https://docs.opendata.aws/amazon-reviews-ml/license.txt) de este dataset.**\n",
    "\n",
    "### Exploración de datos y Procesamiento del Lenguaje Natural\n",
    "\n",
    "Dedícale un buen tiempo a hacer un Análisis Exploratorio de Datos. Considera que hasta que no hayas aplicado las herramientas de Procesamiento del Lenguaje Natural vistas, será difícil completar este análisis. Elige preguntas que creas que puedas responder con este dataset. Por ejemplo, ¿qué palabras están asociadas a calificaciones positivas y qué palabras a calificaciones negativas?\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "Implementa un modelo que, dada la crítica de un producto, asigne la cantidad de estrellas correspondiente. **Para pensar**: ¿es un problema de Clasificación o de Regresión?\n",
    "\n",
    "1. Haz todas las transformaciones de datos que consideres necesarias. Justifica.\n",
    "1. Evalúa de forma apropiada sus resultados. Justifica la métrica elegida.\n",
    "1. Elige un modelo benchmark y compara tus resultados con este modelo.\n",
    "1. Optimiza los hiperparámetros de tu modelo.\n",
    "1. Intenta responder la pregunta: ¿Qué información está usando el modelo para predecir?\n",
    "\n",
    "**Recomendación:** si no te resulta conveniente trabajar en español con NLTK, te recomendamos que explores la librería [spaCy](https://spacy.io/).\n",
    "\n",
    "### Para pensar, investigar y, opcionalmente, implementar\n",
    "1. ¿Valdrá la pena convertir el problema de Machine Learning en un problema binario? Es decir, asignar únicamente las etiquetas Positiva y Negativa a cada crítica y hacer un modelo que, en lugar de predecir las estrellas, prediga esa etiqueta. Pensar en qué situación puede ser útil. ¿Esperas que el desempeño sea mejor o peor?\n",
    "1. ¿Hay algo que te gustaría investigar o probar?\n",
    "\n",
    "### **¡Tómate tiempo para investigar y leer mucho!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x1GFwraSISFB"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0491108</td>\n",
       "      <td>product_es_0296024</td>\n",
       "      <td>reviewer_es_0999081</td>\n",
       "      <td>1</td>\n",
       "      <td>Nada bueno se me fue ka pantalla en menos de 8...</td>\n",
       "      <td>television Nevir</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_0869872</td>\n",
       "      <td>product_es_0922286</td>\n",
       "      <td>reviewer_es_0216771</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible, nos tuvimos que comprar otro porque ...</td>\n",
       "      <td>Dinero tirado a la basura con esta compra</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_0811721</td>\n",
       "      <td>product_es_0474543</td>\n",
       "      <td>reviewer_es_0929213</td>\n",
       "      <td>1</td>\n",
       "      <td>Te obligan a comprar dos unidades y te llega s...</td>\n",
       "      <td>solo llega una unidad cuando te obligan a comp...</td>\n",
       "      <td>es</td>\n",
       "      <td>drugstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_0359921</td>\n",
       "      <td>product_es_0656090</td>\n",
       "      <td>reviewer_es_0224702</td>\n",
       "      <td>1</td>\n",
       "      <td>No entro en descalificar al vendedor, solo pue...</td>\n",
       "      <td>PRODUCTO NO RECIBIDO.</td>\n",
       "      <td>es</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_0068940</td>\n",
       "      <td>product_es_0662544</td>\n",
       "      <td>reviewer_es_0224827</td>\n",
       "      <td>1</td>\n",
       "      <td>Llega tarde y co la talla equivocada</td>\n",
       "      <td>Devuelto</td>\n",
       "      <td>es</td>\n",
       "      <td>shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  es_0491108  product_es_0296024  reviewer_es_0999081      1   \n",
       "1  es_0869872  product_es_0922286  reviewer_es_0216771      1   \n",
       "2  es_0811721  product_es_0474543  reviewer_es_0929213      1   \n",
       "3  es_0359921  product_es_0656090  reviewer_es_0224702      1   \n",
       "4  es_0068940  product_es_0662544  reviewer_es_0224827      1   \n",
       "\n",
       "                                         review_body  \\\n",
       "0  Nada bueno se me fue ka pantalla en menos de 8...   \n",
       "1  Horrible, nos tuvimos que comprar otro porque ...   \n",
       "2  Te obligan a comprar dos unidades y te llega s...   \n",
       "3  No entro en descalificar al vendedor, solo pue...   \n",
       "4               Llega tarde y co la talla equivocada   \n",
       "\n",
       "                                        review_title language product_category  \n",
       "0                                   television Nevir       es      electronics  \n",
       "1          Dinero tirado a la basura con esta compra       es      electronics  \n",
       "2  solo llega una unidad cuando te obligan a comp...       es        drugstore  \n",
       "3                              PRODUCTO NO RECIBIDO.       es         wireless  \n",
       "4                                           Devuelto       es            shoes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json('dataset_es_train.json', lines = True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop_duplicates(inplace = True) #no hay datos duplicados ni faltantes\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id           0\n",
       "product_id          0\n",
       "reviewer_id         0\n",
       "stars               0\n",
       "review_body         0\n",
       "review_title        0\n",
       "language            0\n",
       "product_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "es    200000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.language.value_counts() #solo reseñas en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home                        26962\n",
       "wireless                    25886\n",
       "toy                         13647\n",
       "sports                      13189\n",
       "pc                          11191\n",
       "home_improvement            10879\n",
       "electronics                 10385\n",
       "beauty                       7337\n",
       "automotive                   7143\n",
       "kitchen                      6695\n",
       "apparel                      5737\n",
       "drugstore                    5513\n",
       "book                         5264\n",
       "furniture                    5229\n",
       "baby_product                 4881\n",
       "office_product               4771\n",
       "lawn_and_garden              4237\n",
       "other                        3937\n",
       "pet_products                 3713\n",
       "personal_care_appliances     3573\n",
       "luggage                      3328\n",
       "camera                       3029\n",
       "shoes                        2754\n",
       "digital_ebook_purchase       1843\n",
       "video_games                  1733\n",
       "jewelry                      1598\n",
       "musical_instruments          1530\n",
       "watch                        1490\n",
       "industrial_supplies          1482\n",
       "grocery                      1044\n",
       "Name: product_category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.product_category.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    40000\n",
       "2    40000\n",
       "3    40000\n",
       "4    40000\n",
       "5    40000\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_es_0261843    8\n",
       "product_es_0741712    7\n",
       "product_es_0808483    7\n",
       "product_es_0801630    7\n",
       "product_es_0874126    7\n",
       "                     ..\n",
       "product_es_0412939    1\n",
       "product_es_0307324    1\n",
       "product_es_0756188    1\n",
       "product_es_0233185    1\n",
       "product_es_0301918    1\n",
       "Name: product_id, Length: 150938, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.product_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewer_es_0437514    7\n",
       "reviewer_es_0588051    7\n",
       "reviewer_es_0431022    7\n",
       "reviewer_es_0659252    6\n",
       "reviewer_es_0961357    6\n",
       "                      ..\n",
       "reviewer_es_0298010    1\n",
       "reviewer_es_0953900    1\n",
       "reviewer_es_0749245    1\n",
       "reviewer_es_0898211    1\n",
       "reviewer_es_0435550    1\n",
       "Name: reviewer_id, Length: 179076, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.reviewer_id.value_counts() #product id y reviewer id no deberian coincidir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijo una instancia al azar y veo el review boby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83031 Se me ha fundido una el mismo día que las he puesto. Iluminar, iluminan bastante bien pero estoy algo decepcionado con la que ha dejado de funcionar. El fabricante me envió 1 sin coste alguno para reponer la defectuosa.\n"
     ]
    }
   ],
   "source": [
    "index_random = np.random.randint(0,high = dataset.shape[0])\n",
    "descripcion = dataset.iloc[index_random].review_body\n",
    "print(index_random, descripcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vemos la estrella con la que califico al producto comprado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El comprador 83031\n",
      "Califico al producto con 3 estrellas\n",
      "83031 3\n"
     ]
    }
   ],
   "source": [
    "print (f'El comprador {index_random}')\n",
    "print (f'Califico al producto con {dataset.iloc[index_random].stars} estrellas' )\n",
    "\n",
    "print(index_random, dataset.iloc[index_random].stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.es.examples import sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp (descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se\n",
      "me\n",
      "ha\n",
      "fundido\n",
      "una\n",
      "el\n",
      "mismo\n",
      "día\n",
      "que\n",
      "las\n",
      "he\n",
      "puesto\n",
      ".\n",
      "Iluminar\n",
      ",\n",
      "iluminan\n",
      "bastante\n",
      "bien\n",
      "pero\n",
      "estoy\n",
      "algo\n",
      "decepcionado\n",
      "con\n",
      "la\n",
      "que\n",
      "ha\n",
      "dejado\n",
      "de\n",
      "funcionar\n",
      ".\n",
      "El\n",
      "fabricante\n",
      "me\n",
      "envió\n",
      "1\n",
      "sin\n",
      "coste\n",
      "alguno\n",
      "para\n",
      "reponer\n",
      "la\n",
      "defectuosa\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vemos las stop words que tiene identificada Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mia', 'vosotros', 'antes', 'encuentra', 'lo', 'era', 'se', 'dan', 'considera', 'demasiado', 'último', 'nuestras', 'ultimo', 'consideró', 'aproximadamente', 'dice', 'saben', 'solamente', 'si', 'cuál', 'esa', 'podrian', 'he', 'nuevos', 'serán', 'realizado', 'míos', 'cuánta', 'será', 'su', 'vuestro', 'sí', 'los', 'tiempo', 'trabajas', 'mios', 'indicó', 'otras', 'usa', 'soyos', 'ésos', 'habla', 'menos', 'ella', 'eso', 'salvo', 'tenemos', 'diferente', 'nueva', 'poco', 'propio', 'las', 'han', 'ayer', 'intentas', 'decir', 'unos', 'pocas', 'anterior', 'el', 'quedó', 'dias', 'pasada', 'tiene', 'bueno', 'fueron', 'dia', 'cerca', 'apenas', 'nosotras', 'ver', 'durante', 'ésta', 'buenos', 'todavia', 'fin', 'hizo', 'conseguir', 'entonces', 'eramos', 'esto', 'tengo', 'ninguno', 'existe', 'estos', 'quiza', 'allí', 'cualquier', 'alguno', 'con', 'ésas', 'fuimos', 'aunque', 'podrán', 'tras', 'según', 'segun', 'enseguida', 'ahi', 'cuando', 'sobre', 'consigo', 'sabemos', 'demás', 'él', 'había', 'estuvo', 'comentó', 'también', 'éstos', 'uno', 'tus', 'ser', 'haciendo', 'solos', 'hemos', 'eran', 'podria', 'son', 'últimas', 'ex', 'conseguimos', 'usar', 'usais', 'misma', 'la', 'momento', 'podrias', 'va', 'dónde', 'antano', 'ningunas', 'cosas', 'tenía', 'vez', 'quienes', 'vaya', 'manera', 'nada', 'fue', 'repente', 'intentan', 'estaban', 'estas', 'ello', 'sea', 'podemos', 'últimos', 'vuestras', 'usamos', 'unas', 'conmigo', 'algún', 'empleais', 'sola', 'general', 'usan', 'ustedes', 'realizar', 'aquellas', 'primera', 'estados', 'vosotras', 'intentamos', 'cierta', 'añadió', 'una', 'debido', 'tendrá', 'bajo', 'tuyas', 'cuáles', 'puedo', 'respecto', 'sólo', 'van', 'cinco', 'cuanto', 'dentro', 'trabajais', 'cierto', 'ningún', 'horas', 'tú', 'entre', 'les', 'verdadero', 'empleas', 'dicen', 'quien', 'aquel', 'contigo', 'os', 'mas', 'vuestra', 'realizó', 'tu', 'modo', 'afirmó', 'cuándo', 'te', 'aquí', 'otro', 'casi', 'pudo', 'vuestros', 'varios', 'sigue', 'manifestó', 'conocer', 'somos', 'paìs', 'igual', 'detras', 'hicieron', 'hasta', 'vais', 'arriba', 'cuanta', 'dado', 'medio', 'hacer', 'cuatro', 'le', 'lugar', 'llevar', 'sera', 'podriais', 'propias', 'temprano', 'dijo', 'pero', 'nuestros', 'detrás', 'trabajan', 'aquéllas', 'ése', 'haya', 'agregó', 'alrededor', 'empleo', 'poder', 'largo', 'claro', 'tienen', 'eras', 'dio', 'uso', 'cuales', 'tuyo', 'arribaabajo', 'cuantos', 'algunas', 'para', 'éstas', 'estará', 'desde', 'muy', 'este', 'aún', 'alguna', 'existen', 'quién', 'teneis', 'sabes', 'mediante', 'proximo', 'mejor', 'toda', 'mismos', 'intenta', 'podriamos', 'tal', 'tanto', 'más', 'emplear', 'mía', 'podeis', 'aqui', 'despues', 'muchas', 'hacerlo', 'intentais', 'quiénes', 'vamos', 'muchos', 'habrá', 'suyo', 'ante', 'debe', 'principalmente', 'ambos', 'nos', 'aquellos', 'sean', 'aseguró', 'pais', 'buen', 'ocho', 'ahí', 'suyas', 'posible', 'través', 'qué', 'verdad', 'nadie', 'usas', 'lleva', 'nuevo', 'gran', 'ningunos', 'están', 'suya', 'primer', 'hago', 'adrede', 'no', 'dar', 'hablan', 'poca', 'acuerdo', 'sabe', 'trata', 'voy', 'hacia', 'nuestra', 'haceis', 'días', 'mencionó', 'que', 'mío', 'final', 'pues', 'segunda', 'después', 'ejemplo', 'aquello', 'donde', 'así', 'podrían', 'nunca', 'ese', 'tambien', 'saber', 'encima', 'tenga', 'tuvo', 'hoy', 'siempre', 'breve', 'mucha', 'mucho', 'pesar', 'segundo', 'hecho', 'valor', 'sabeis', 'otros', 'poner', 'tampoco', 'aquél', 'soy', 'debajo', 'mismas', 'tercera', 'éste', 'pasado', 'podrá', 'estaba', 'tenido', 'buenas', 'en', 'cuenta', 'mal', 'todavía', 'llegó', 'solo', 'verdadera', 'esta', 'lejos', 'cuánto', 'menudo', 'mismo', 'ya', 'aquéllos', 'pocos', 'algunos', 'asi', 'gueno', 'aun', 'trabajamos', 'parece', 'informó', 'podría', 'cuantas', 'algo', 'yo', 'diferentes', 'cuántas', 'ampleamos', 'hay', 'ciertas', 'estan', 'junto', 'buena', 'deprisa', 'aquélla', 'emplean', 'esas', 'nuevas', 'queremos', 'ésa', 'consiguen', 'mis', 'ellas', 'supuesto', 'mias', 'sois', 'tan', 'da', 'informo', 'un', 'mientras', 'sino', 'estado', 'antaño', 'propia', 'está', 'dijeron', 'luego', 'quiere', 'hacen', 'ti', 'siendo', 'mio', 'alli', 'tuya', 'cómo', 'haces', 'grandes', 'parte', 'sido', 'ellos', 'esos', 'dos', 'trabaja', 'propios', 'además', 'estamos', 'cada', 'pueda', 'me', 'pronto', 'haber', 'mi', 'trabajo', 'despacio', 'hacemos', 'es', 'otra', 'primero', 'todos', 'partir', 'dieron', 'cual', 'deben', 'consigue', 'al', 'sé', 'expresó', 'de', 'enfrente', 'creo', 'aquella', 'como', 'dejó', 'hubo', 'excepto', 'fui', 'ir', 'usted', 'veces', 'explicó', 'lado', 'por', 'embargo', 'ahora', 'tuyos', 'nosotros', 'última', 'sin', 'fuera', 'ademas', 'peor', 'todo', 'varias', 'siguiente', 'intento', 'pueden', 'estar', 'estoy', 'delante', 'estais', 'mayor', 'consigues', 'seis', 'tendrán', 'incluso', 'cuántos', 'qeu', 'bien', 'habia', 'total', 'trabajar', 'del', 'contra', 'nuestro', 'sería', 'ha', 'porque', 'próximos', 'bastante', 'solas', 'mías', 'hace', 'quizas', 'ni', 'actualmente', 'adelante', 'tener', 'eres', 'tres', 'atras', 'sus', 'señaló', 'ninguna', 'dicho', 'tarde', 'intentar', 'próximo', 'todas', 'primeros', 'quizá', 'siete', 'ciertos', 'raras', 'mí', 'habían', 'puede', 'quizás', 'día']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "stopwords_spacy = list(STOP_WORDS)\n",
    "print (stopwords_spacy)\n",
    "len(stopwords_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos las palabras del texto que no son stop words según Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fundido\n",
      "puesto\n",
      ".\n",
      "Iluminar\n",
      ",\n",
      "iluminan\n",
      "decepcionado\n",
      "dejado\n",
      "funcionar\n",
      ".\n",
      "fabricante\n",
      "envió\n",
      "1\n",
      "coste\n",
      "reponer\n",
      "defectuosa\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.is_stop == False:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se él\n",
      "me yo\n",
      "ha haber\n",
      "fundido fundir\n",
      "una uno\n",
      "el el\n",
      "mismo mismo\n",
      "día día\n",
      "que que\n",
      "las él\n",
      "he haber\n",
      "puesto poner\n",
      ". .\n",
      "Iluminar iluminar\n",
      ", ,\n",
      "iluminan iluminar\n",
      "bastante bastante\n",
      "bien bien\n",
      "pero pero\n",
      "estoy estar\n",
      "algo algo\n",
      "decepcionado decepcionado\n",
      "con con\n",
      "la el\n",
      "que que\n",
      "ha haber\n",
      "dejado dejar\n",
      "de de\n",
      "funcionar funcionar\n",
      ". .\n",
      "El el\n",
      "fabricante fabricante\n",
      "me yo\n",
      "envió enviar\n",
      "1 1\n",
      "sin sin\n",
      "coste coste\n",
      "alguno alguno\n",
      "para para\n",
      "reponer reponer\n",
      "la el\n",
      "defectuosa defectuosa\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print (token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POS Part of Speech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se PRON\n",
      "me PRON\n",
      "ha AUX\n",
      "fundido VERB\n",
      "una DET\n",
      "el DET\n",
      "mismo DET\n",
      "día NOUN\n",
      "que PRON\n",
      "las PRON\n",
      "he AUX\n",
      "puesto VERB\n",
      ". PUNCT\n",
      "Iluminar VERB\n",
      ", PUNCT\n",
      "iluminan VERB\n",
      "bastante ADV\n",
      "bien ADV\n",
      "pero CCONJ\n",
      "estoy AUX\n",
      "algo PRON\n",
      "decepcionado ADJ\n",
      "con ADP\n",
      "la DET\n",
      "que PRON\n",
      "ha AUX\n",
      "dejado VERB\n",
      "de ADP\n",
      "funcionar VERB\n",
      ". PUNCT\n",
      "El DET\n",
      "fabricante NOUN\n",
      "me PRON\n",
      "envió VERB\n",
      "1 NUM\n",
      "sin ADP\n",
      "coste NOUN\n",
      "alguno PRON\n",
      "para ADP\n",
      "reponer VERB\n",
      "la DET\n",
      "defectuosa NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print (token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detección de identidades**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Se me ha fundido una el mismo día que las he puesto. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Iluminar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", iluminan bastante bien pero estoy algo decepcionado con la que ha dejado de funcionar. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    El fabricante me envió 1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " sin coste alguno para reponer la defectuosa.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = 'ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenización**\n",
    "\n",
    "Eliminamos los signos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~¿!¡? + \" \"'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "puntua = string.punctuation + '¿!¡? + \" \"'\n",
    "puntua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_data_cleaning(sentence):\n",
    "    doc=nlp(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != '-PRON-':\n",
    "            temp= token.lemma_.strip()\n",
    "        else:\n",
    "            temp = token\n",
    "        tokens.append(temp)\n",
    "        \n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords_spacy and token not in puntua:\n",
    "            clean_tokens.append(token)\n",
    "            \n",
    "    return clean_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fundir',\n",
       " 'iluminar',\n",
       " 'iluminar',\n",
       " 'decepcionado',\n",
       " 'dejar',\n",
       " 'funcionar',\n",
       " 'fabricante',\n",
       " 'enviar',\n",
       " '1',\n",
       " 'coste',\n",
       " 'reponer',\n",
       " 'defectuosa']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_cleaning(descripcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorización TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['review_body']\n",
    "y = dataset['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153248            Muy buen tamaño, cumple las expectativas.\n",
       "67802     A los pocos meses no se podía llamar. Era para...\n",
       "148889    LO HE USADO POCO PERO DESPRENDE BUEN VOLUMEN D...\n",
       "103093    Funciona bien, pero devuelto porque la radio e...\n",
       "104681    Para niños pequeños es un problema el puzzle p...\n",
       "Name: review_body, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PENDIENTES##\n",
    "\n",
    "terminar de hacer vectorizacion. \n",
    "\n",
    "Pense en dividir el DS en dos. uno que tenga los comentarios de las personas que hayan puntuado entre 1 y 3 estrellas y el otro con el de 4 y 5 y buscar cuales son las palabras que mas se repiten en ambos. Quizas al dividir en dos el df se distribuyen de diferente manera las product_Category y podemos ver si algunas tienen mayor tendencia a tener malas puntuaciones. o cuales son las catergorias con mejor puntuacion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Proyecto_03_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
